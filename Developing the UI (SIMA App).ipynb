{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06703e15-eeca-4d2b-972a-3e7c072f21bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from PyQt5 import QtWidgets, QtCore\n",
    "from PyQt5.QtWidgets import QApplication, QMainWindow, QLabel, QWidget, QVBoxLayout, QFileDialog\n",
    "from PyQt5.QtGui import QPixmap, QFont\n",
    "\n",
    "class MyWindow(QMainWindow):\n",
    "    def __init__(self):\n",
    "        super(MyWindow, self).__init__()\n",
    "        self.setGeometry(660, 240, 500, 500)\n",
    "        self.setWindowTitle(\"SIMA (Speech Intelligibility Mosque Analyzer)\")\n",
    "        self.setStyleSheet(\"background-color: white;\")\n",
    "        self.initUI()\n",
    "\n",
    "    def initUI(self):\n",
    "        central_widget = QWidget(self)\n",
    "        self.setCentralWidget(central_widget)\n",
    "\n",
    "        layout = QVBoxLayout()\n",
    "        layout.setAlignment(QtCore.Qt.AlignTop)\n",
    "\n",
    "        # Path relatif logo (bisa diganti sesuai kebutuhan)\n",
    "        img_path2 = os.path.join(\"C:/Users/ndaru/OneDrive - KFUPM/THESIS/DATASET/Apps/kfupm logo.png\")\n",
    "        pixmap2 = QPixmap(img_path2).scaled(75, 75, QtCore.Qt.KeepAspectRatio, QtCore.Qt.SmoothTransformation)\n",
    "\n",
    "        self.lbl_img = QLabel(self)\n",
    "        self.lbl_img.setPixmap(pixmap2)\n",
    "        self.lbl_img.setAlignment(QtCore.Qt.AlignCenter)\n",
    "        layout.addWidget(self.lbl_img, alignment=QtCore.Qt.AlignHCenter)\n",
    "\n",
    "        layout.addSpacing(10)\n",
    "\n",
    "        self.lbl_dept = QLabel(\"Architectural Engineering and Construction Management Department\", self)\n",
    "        self.lbl_dept.setFont(QFont(\"Arial\", 8))\n",
    "        self.lbl_dept.setAlignment(QtCore.Qt.AlignCenter)\n",
    "        layout.addWidget(self.lbl_dept)\n",
    "\n",
    "        self.lbl_college = QLabel(\"College of Design and Built Environment\", self)\n",
    "        self.lbl_college.setFont(QFont(\"Arial\", 8))\n",
    "        self.lbl_college.setAlignment(QtCore.Qt.AlignCenter)\n",
    "        layout.addWidget(self.lbl_college)\n",
    "\n",
    "        self.lbl_university = QLabel(\"King Fahd University of Petroleum and Minerals\", self)\n",
    "        self.lbl_university.setFont(QFont(\"Arial\", 8))\n",
    "        self.lbl_university.setAlignment(QtCore.Qt.AlignCenter)\n",
    "        layout.addWidget(self.lbl_university)\n",
    "\n",
    "        layout.addSpacing(50)\n",
    "\n",
    "        self.lbl_welcome = QLabel(\"Welcome to:\", self)\n",
    "        self.lbl_welcome.setFont(QFont(\"Arial\", 8))\n",
    "        self.lbl_welcome.setAlignment(QtCore.Qt.AlignCenter)\n",
    "        layout.addWidget(self.lbl_welcome)\n",
    "\n",
    "        layout.addSpacing(30)\n",
    "\n",
    "        self.lbl_sima = QLabel(\"SIMA\", self)\n",
    "        self.lbl_sima.setFont(QFont(\"Eras Demi ITC\", 35))\n",
    "        self.lbl_sima.setAlignment(QtCore.Qt.AlignCenter)\n",
    "        layout.addWidget(self.lbl_sima)\n",
    "\n",
    "        self.lbl_simal = QLabel(\"Speech Intelligibility Mosque Analyzer\", self)\n",
    "        self.lbl_simal.setFont(QFont(\"Eras Demi ITC\", 15))\n",
    "        self.lbl_simal.setAlignment(QtCore.Qt.AlignCenter)\n",
    "        layout.addWidget(self.lbl_simal)\n",
    "\n",
    "        layout.addSpacing(50)\n",
    "\n",
    "        self.btn_browse = QtWidgets.QPushButton(\"Browse Impulse Response (.wav) File\", self)\n",
    "        self.btn_browse.setFont(QFont(\"Arial\", 9))\n",
    "        self.btn_browse.clicked.connect(self.browse_file)\n",
    "        layout.addWidget(self.btn_browse)\n",
    "\n",
    "        self.lbl_path = QtWidgets.QLabel(\"Selected file will appear here\", self)\n",
    "        self.lbl_path.setFont(QFont(\"Arial\", 9))\n",
    "        self.lbl_path.setAlignment(QtCore.Qt.AlignCenter)\n",
    "        layout.addWidget(self.lbl_path)\n",
    "\n",
    "        layout.addSpacing(30)\n",
    "\n",
    "        self.btn_predict = QtWidgets.QPushButton(\"Predict\", self)\n",
    "        self.btn_predict.setFont(QFont(\"Arial\", 9))\n",
    "        self.btn_predict.clicked.connect(self.predict)\n",
    "        layout.addWidget(self.btn_predict)\n",
    "\n",
    "        self.lbl_result = QtWidgets.QLabel(\"Result will appear here\", self)\n",
    "        self.lbl_result.setFont(QFont(\"Arial\", 9, QFont.Bold))\n",
    "        self.lbl_result.setAlignment(QtCore.Qt.AlignCenter)\n",
    "        layout.addWidget(self.lbl_result)\n",
    "\n",
    "        central_widget.setLayout(layout)\n",
    "\n",
    "    def browse_file(self):\n",
    "        file_path, _ = QFileDialog.getOpenFileName(self, \"Select a WAV file\", \"\", \"WAV Files (*.wav)\")\n",
    "        if file_path:\n",
    "            self.lbl_path.setText(file_path)\n",
    "        else:\n",
    "            self.lbl_path.setText(\"No file selected.\")\n",
    "\n",
    "    def predict(self):\n",
    "        import numpy as np\n",
    "        import librosa\n",
    "        import soundfile as sf\n",
    "        import tensorflow as tf\n",
    "        from scipy.signal import butter, sosfilt\n",
    "\n",
    "        SR = 22050\n",
    "        N_MFCC = 13\n",
    "        N_FFT = 2048\n",
    "        HOP_LENGTH = 128\n",
    "        DURATION = 4.0\n",
    "        SAMPLES_PER_TRACK = int(SR * DURATION)\n",
    "\n",
    "        from keras.layers import TFSMLayer\n",
    "        from keras import Sequential\n",
    "        \n",
    "        model_path = \"C:/Users/ndaru/OneDrive - KFUPM/THESIS/DATASET/Apps/cnn_audio_model2\"\n",
    "        layer = TFSMLayer(model_path, call_endpoint=\"serve\")\n",
    "        model = Sequential([layer])\n",
    "\n",
    "        def bandpass_filter(signal, sr, lowcut=250, highcut=2000, order=5):\n",
    "            sos = butter(order, [lowcut, highcut], btype='band', fs=sr, output='sos')\n",
    "            return sosfilt(sos, signal)\n",
    "\n",
    "        def extract_mfcc_stereo(file_path):\n",
    "            signal, sample_rate = librosa.load(file_path, sr=SR, mono=False)\n",
    "\n",
    "            if signal.shape[1] < SAMPLES_PER_TRACK:\n",
    "                pad_length = int(SAMPLES_PER_TRACK - signal.shape[1])\n",
    "                signal = np.pad(signal, ((0, 0), (0, pad_length)), mode=\"constant\")\n",
    "            elif signal.shape[1] > SAMPLES_PER_TRACK:\n",
    "                signal = signal[:, :SAMPLES_PER_TRACK]\n",
    "\n",
    "            left_channel = bandpass_filter(signal[0], sample_rate)\n",
    "            right_channel = bandpass_filter(signal[1], sample_rate)\n",
    "\n",
    "            mfcc_left = librosa.feature.mfcc(y=left_channel, sr=SR, n_mfcc=N_MFCC, n_fft=N_FFT, hop_length=HOP_LENGTH).T\n",
    "            mfcc_right = librosa.feature.mfcc(y=right_channel, sr=SR, n_mfcc=N_MFCC, n_fft=N_FFT, hop_length=HOP_LENGTH).T\n",
    "\n",
    "            mfcc_left = (mfcc_left - np.mean(mfcc_left, axis=0)) / (np.std(mfcc_left, axis=0) + 1e-10)\n",
    "            mfcc_right = (mfcc_right - np.mean(mfcc_right, axis=0)) / (np.std(mfcc_right, axis=0) + 1e-10)\n",
    "\n",
    "            feature = np.stack((mfcc_left, mfcc_right), axis=-1)\n",
    "            feature = feature[..., np.newaxis]\n",
    "\n",
    "            return feature\n",
    "\n",
    "        def classify(file_path):\n",
    "            X = extract_mfcc_stereo(file_path)\n",
    "            X = np.expand_dims(X, axis=0)\n",
    "\n",
    "            prediction = model.predict(X)\n",
    "            predicted_label = (prediction[:, 1] > 0.5).astype(int)\n",
    "            \n",
    "            class_names = [\"High Intelligibility\", \"Low Intelligibility\"]\n",
    "            predicted_label_name = class_names[int(predicted_label[0])]\n",
    "\n",
    "            probabilities_percent = prediction[0] * 100\n",
    "            prob_string = \", \".join([f\"{class_names[i]}: {probabilities_percent[i]:.1f}%\" for i in range(len(class_names))])\n",
    "\n",
    "            self.lbl_result.setText(f\"Predicted class: {predicted_label_name} ({prob_string})\")\n",
    "            return predicted_label_name\n",
    "\n",
    "        audio_file = self.lbl_path.text()\n",
    "        if os.path.exists(audio_file):\n",
    "            classify(audio_file)\n",
    "        else:\n",
    "            self.lbl_result.setText(\"No valid file selected.\")\n",
    "\n",
    "def window():\n",
    "    app = QApplication(sys.argv)\n",
    "    win = MyWindow()\n",
    "    win.show()\n",
    "    sys.exit(app.exec_())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    window()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
